{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a6T1vnVygY3",
    "outputId": "4340d1d4-8699-449f-e667-21465000fcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.11/site-packages (3.8.4)\n",
      "Collecting image_classifiers\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/mamba/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7 (from image_classifiers)\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: keras-applications, image_classifiers\n",
      "Successfully installed image_classifiers-1.0.0 keras-applications-1.0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 13:31:28.869892: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-12 13:31:29.752140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib image_classifiers tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, UpSampling2D, Dropout, RandomFlip, RandomTranslation, RandomRotation,RandomBrightness, RandomContrast, RandomZoom, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "from keras.models import Model\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import linear\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HJBnQzTj-I-v"
   },
   "outputs": [],
   "source": [
    "n_epoch = 100 # Il y a le early stopping\n",
    "batch_size = 100\n",
    "taux_validation = 0.1\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[32;1mmc: \u001b[0m\u001b[32;1mConfiguration written to `/home/onyxia/.mc/config.json`. Please update your access credentials.\u001b[0;22m\n",
      "\u001b[32;1mmc: \u001b[0m\u001b[32;1mSuccessfully created `/home/onyxia/.mc/share`.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share uploads `/home/onyxia/.mc/share/uploads.json` file.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share downloads `/home/onyxia/.mc/share/downloads.json` file.\n",
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 95.42 MiB/s 1s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-12 13:31:38.912422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 722 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.0 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MLyUvI1U-J0N"
   },
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "augmentation_donnees_keras = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.2,0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2,value_range=(0,1))\n",
    "])\n",
    "\n",
    "def augmentation_donnees(image, label):\n",
    "    return augmentation_donnees_keras(image/255.0, training = True)*255.0, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def train_val_split(train_dataset, validation_size):\n",
    "    X_train, y_train = train_dataset\n",
    "    indices = np.random.permutation(X_train.shape[0])\n",
    "    train_idx, val_idx = indices[:train_size], indices[train_size:]\n",
    "    return (X_train[train_idx,...], y_train[train_idx,...]), (X_train[val_idx,...], y_train[val_idx,...])\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "\n",
    "validation_size = int(n_images * taux_validation)\n",
    "train_size = n_images - validation_size\n",
    "\n",
    "train_dataset, validation_dataset = train_val_split(train_dataset, validation_size)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet).cache().prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).map(preprocessing).cache().repeat().shuffle(train_size).batch(batch_size).map(augmentation_donnees, num_parallel_calls = 2).map(preprocess_resnet, num_parallel_calls = 2).prefetch(2)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "g_WFfeF--Sz2",
    "outputId": "11ccfa14-574a-47d3-9483-253c6e0b708a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected ':' (540604782.py, line 69)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[5], line 69\u001b[0;36m\u001b[0m\n\u001b[0;31m    else if early_stop_count > 5:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
     ]
    }
   ],
   "source": [
    "def get_modele_logits(modele):\n",
    "    config = modele.layers[-1].get_config()\n",
    "    config['activation'] = linear\n",
    "    config['name'] = 'logits'\n",
    "    res = Model(inputs=modele.inputs, outputs=[Dense(**config)(modele.layers[-2].output)])\n",
    "    res.layers[-1].set_weights([x.numpy() for x in modele.layers[-1].weights])\n",
    "    res.compile(metrics=['accuracy'])\n",
    "    return res\n",
    "\n",
    "@tf.function\n",
    "def compte_bons(x,y):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(tf.argmax(x, axis = 1), tf.argmax(y, axis = 1)), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def softmax(logits, temp):\n",
    "    expo = tf.exp(logits / temp)\n",
    "    return expo / tf.reduce_sum(expo, axis = 1, keepdims=True)\n",
    "\n",
    "@tf.function\n",
    "def ce(x, y, temp):\n",
    "    res = - x * tf.math.log(y)\n",
    "    res = tf.where(tf.math.is_nan(res), 0., res)\n",
    "    res = tf.reduce_sum(res) * temp**2\n",
    "    return res\n",
    "\n",
    "def init_csv_log(fichier):\n",
    "    with open(fichier,'w') as file:\n",
    "        file.write(\"epoch, accuracy,val_accuracy\\n\")\n",
    "def append_csv_log(fichier, epoch, accuracy,val_accuracy):\n",
    "    with open(fichier,'a') as file:\n",
    "        file.write(f\"{epoch:d},{accuracy:.2f},{val_accuracy:.2f}\\n\")\n",
    "\n",
    "def distillateur_kl(etudiant, enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch, alpha):\n",
    "    etudiant_logit = get_modele_logits(etudiant)\n",
    "    enseignant_logit = get_modele_logits(enseignant)\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    init_csv_log(f\"sauvegardes/{nom_modele}.csv\")\n",
    "    print(\"C'est parti pour la distillation !\\n\")\n",
    "    val_accuracy_max = 0\n",
    "    val_loss_min = 0\n",
    "    early_stop_count = 0\n",
    "    train_dataset_iter = iter(train_dataset)\n",
    "    for epoch in range(n_epoch):\n",
    "        print(f\"Époque {epoch + 1} / {n_epoch}\")\n",
    "        n_batch = train_size//batch_size\n",
    "        barre_progression = tqdm(range(n_batch))\n",
    "        bons_epoque = 0\n",
    "        for i in barre_progression:\n",
    "            X_batch, y_batch = next(train_dataset_iter)\n",
    "            enseignant_estim_logit = enseignant_logit(X_batch, training = False)\n",
    "            enseignant_estim_softmax = softmax(enseignant_estim_logit, temp)\n",
    "            with tf.GradientTape() as tape:\n",
    "                etudiant_estim_logit = etudiant_logit(X_batch, training = True)\n",
    "                etudiant_estim_softmax = softmax(etudiant_estim_logit, temp)\n",
    "                etudiant_estim_softmax_1 = softmax(etudiant_estim_logit, 1)\n",
    "                perte = alpha * ce(y_batch,etudiant_estim_softmax, 1) + (1-alpha) * ce(enseignant_estim_softmax,etudiant_estim_softmax, temp)\n",
    "            grads = tape.gradient(perte, etudiant_logit.trainable_variables)\n",
    "            adam.apply_gradients(zip(grads, etudiant_logit.trainable_variables))\n",
    "            bons_epoque += compte_bons(etudiant_estim_softmax,y_batch).numpy()\n",
    "            accuracy = bons_epoque / (i * batch_size) if i != 0 else np.nan\n",
    "            barre_progression.set_description(f\"Accuracy {accuracy*100:.1f} %\")\n",
    "        val_loss, val_accuracy = etudiant.evaluate(validation_dataset)\n",
    "        if val_accuracy > val_accuracy_max:\n",
    "            val_accuracy_max = val_accuracy\n",
    "            etudiant.save(f\"sauvegardes/{nom_modele}_checkpoint.keras\")\n",
    "        if val_loss < val_loss_min:\n",
    "            val_loss_min = val_loss\n",
    "            early_stop_count = 0\n",
    "        elif early_stop_count > 5:\n",
    "            return\n",
    "        else early_stop_count += 1\n",
    "        append_csv_log(f\"sauvegardes/{nom_modele}.csv\", epoch, accuracy, val_accuracy)\n",
    "        print(f\"Accuracy (train) : {accuracy:.4f} | Accuracy (val) : {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_resnet18(temp, alpha):\n",
    "    tf.keras.backend.clear_session()\n",
    "    modele = new_modele_resnet()\n",
    "    nom_modele =  f\"model_etudiant_t{temp:d}_a{int(alpha*100):d}\"\n",
    "    distillateur_kl(modele, model_enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch,0.25)\n",
    "    wd = os.getcwd()\n",
    "    os.system(f\"cp {wd}/sauvegardes/{nom_modele}_checkpoint.keras {wd}/sauvegardes/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}.keras s3/afeldmann/projet_cnam/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}.csv s3/afeldmann/projet_cnam/{nom_modele}.csv\")\n",
    "    history=np.genfromtxt(f\"sauvegardes/{nom_modele}_logs.csv\", delimiter=\",\", names = True)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Modèle enseignant')\n",
    "    plt.ylabel('Exactitude')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.axvline(x=47, color='purple', ls='--', lw=2, label='Limite réglage fin')\n",
    "    plt.legend(['Entrainement', 'Validation','Limite réglage fin'], loc='best')\n",
    "    plt.show()\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title('Modèle enseignant')\n",
    "    plt.ylabel('Perte')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.axvline(x=47, color='purple', ls='--', lw=2, label='Limite réglage fin')\n",
    "    plt.legend(['Entrainement', 'Validation','Limite réglage fin'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(1,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(3,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(8,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distillation_resnet18' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistillation_resnet18\u001b[49m(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distillation_resnet18' is not defined"
     ]
    }
   ],
   "source": [
    "distillation_resnet18(3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distillation_resnet18' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistillation_resnet18\u001b[49m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'distillation_resnet18' is not defined"
     ]
    }
   ],
   "source": [
    "distillation_resnet18(8,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9bONC3xH3xaW7dDlmJISS",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "106xzOLKiTWG5i8p3_sRoYD7Xjz-gmRDB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
