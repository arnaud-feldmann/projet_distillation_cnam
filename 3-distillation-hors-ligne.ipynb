{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a6T1vnVygY3",
    "outputId": "4340d1d4-8699-449f-e667-21465000fcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting image_classifiers\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: tqdm in /opt/mamba/lib/python3.11/site-packages (4.66.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.5/159.5 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Collecting keras-applications<=1.0.8,>=1.0.7 (from image_classifiers)\n",
      "  Downloading Keras_Applications-1.0.8-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Downloading contourpy-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (306 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.0/306.0 kB\u001b[0m \u001b[31m83.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.3.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m84.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyparsing, pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib, keras-applications, image_classifiers\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 image_classifiers-1.0.0 keras-applications-1.0.8 kiwisolver-1.4.5 matplotlib-3.8.4 pillow-10.3.0 pyparsing-3.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 07:18:56.757891: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-14 07:18:57.634551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib image_classifiers tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, RandomFlip, RandomTranslation, RandomRotation,RandomBrightness, RandomContrast, RandomZoom, GlobalAveragePooling2D\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "from keras.models import Model\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import linear\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.utils import Progbar\n",
    "from tensorflow.nn import softmax_cross_entropy_with_logits\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HJBnQzTj-I-v"
   },
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 64\n",
    "taux_validation = 0.1\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b]11;?\u001b\\\u001b[6n\u001b[32;1mmc: \u001b[0m\u001b[32;1mConfiguration written to `/home/onyxia/.mc/config.json`. Please update your access credentials.\u001b[0;22m\n",
      "\u001b[32;1mmc: \u001b[0m\u001b[32;1mSuccessfully created `/home/onyxia/.mc/share`.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share uploads `/home/onyxia/.mc/share/uploads.json` file.\n",
      "\u001b[0m\u001b[32;1mmc: \u001b[0m\u001b[32;1mInitialized share downloads `/home/onyxia/.mc/share/downloads.json` file.\n",
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 94.40 MiB/s 1s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 07:19:06.169156: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94668760/94668760\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.0 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MLyUvI1U-J0N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
      "\u001b[1m169001437/169001437\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "augmentation_donnees_keras = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.2,0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2,value_range=(0,1))\n",
    "])\n",
    "\n",
    "def augmentation_donnees(image, label):\n",
    "    return augmentation_donnees_keras(image/255.0, training = True)*255.0, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def train_val_split(train_dataset, validation_size):\n",
    "    X_train, y_train = train_dataset\n",
    "    indices = np.random.permutation(X_train.shape[0])\n",
    "    train_idx, val_idx = indices[:train_size], indices[train_size:]\n",
    "    return (X_train[train_idx,...], y_train[train_idx,...]), (X_train[val_idx,...], y_train[val_idx,...])\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "\n",
    "validation_size = int(n_images * taux_validation)\n",
    "train_size = n_images - validation_size\n",
    "\n",
    "train_dataset, validation_dataset = train_val_split(train_dataset, validation_size)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet).cache().prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).map(preprocessing).cache().repeat().shuffle(train_size).batch(batch_size).map(augmentation_donnees, num_parallel_calls = tf.data.AUTOTUNE).map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "g_WFfeF--Sz2",
    "outputId": "11ccfa14-574a-47d3-9483-253c6e0b708a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_modele_logits(modele):\n",
    "    config = modele.layers[-1].get_config()\n",
    "    config['activation'] = linear\n",
    "    config['name'] = 'logits'\n",
    "    res = Model(inputs=modele.inputs, outputs=[Dense(**config)(modele.layers[-2].output)])\n",
    "    res.layers[-1].set_weights([x.numpy() for x in modele.layers[-1].weights])\n",
    "    res.compile(metrics=['accuracy'])\n",
    "    return res\n",
    "\n",
    "@tf.function\n",
    "def compte_bons(x,y):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(tf.argmax(x, axis = 1), tf.argmax(y, axis = 1)), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def softmax(logits, temp):\n",
    "    expo = tf.exp(logits / temp)\n",
    "    return expo / tf.reduce_sum(expo, axis = 1, keepdims=True)\n",
    "\n",
    "@tf.function\n",
    "def ce(x, y_logits, temp):\n",
    "    return softmax_cross_entropy_with_logits(x, y_logits / temp) * temp**2\n",
    "\n",
    "def init_csv_log(fichier):\n",
    "    with open(fichier,'w') as file:\n",
    "        file.write(\"epoch, accuracy,val_accuracy\\n\")\n",
    "def append_csv_log(fichier, epoch, accuracy,val_accuracy):\n",
    "    with open(fichier,'a') as file:\n",
    "        file.write(f\"{epoch:d},{accuracy:.2f},{val_accuracy:.2f}\\n\")\n",
    "\n",
    "@tf.function\n",
    "def forward_backward_pass(train_dataset_iter, etudiant_logit_model, alpha, temp, adam):\n",
    "    X_batch, y_batch, enseignant_estim_softmax = next(train_dataset_iter)\n",
    "    with tf.GradientTape() as tape:\n",
    "        etudiant_estim_logit = etudiant_logit_model(X_batch, training = True)\n",
    "        perte = alpha * softmax_cross_entropy_with_logits(y_batch,etudiant_estim_logit) + (1-alpha) * ce(enseignant_estim_softmax,etudiant_estim_logit, temp)\n",
    "    grads = tape.gradient(perte, etudiant_logit_model.trainable_variables)\n",
    "    adam.apply_gradients(zip(grads, etudiant_logit_model.trainable_variables))\n",
    "    return compte_bons(etudiant_estim_logit,y_batch)\n",
    "\n",
    "def distillateur_kl(etudiant, enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch, alpha):\n",
    "    etudiant_logit_model = get_modele_logits(etudiant)\n",
    "    enseignant_logit_model = get_modele_logits(enseignant)\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    init_csv_log(f\"sauvegardes/{nom_modele}_logs.csv\")\n",
    "    print(\"C'est parti pour la distillation !\\n\")\n",
    "    val_accuracy_max = 0\n",
    "    train_dataset_iter = iter(\n",
    "        train_dataset\n",
    "        .map(lambda images, label: (images, label, softmax(enseignant_logit_model(images, training = False), temp)), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    for epoch in range(n_epoch):\n",
    "        print(f\"Époque {epoch + 1} / {n_epoch}\")\n",
    "        n_batch = train_size//batch_size\n",
    "        barre_progression = Progbar(n_batch, stateful_metrics = [\"acc\"])\n",
    "        bons_epoque = 0\n",
    "        for i in range(n_batch):\n",
    "            bons_epoque += forward_backward_pass(train_dataset_iter, etudiant_logit_model, alpha, temp, adam).numpy()\n",
    "            accuracy = bons_epoque / ((i+1) * batch_size)\n",
    "            barre_progression.update(i + 1, values = [(\"acc\", accuracy)])\n",
    "        _, val_accuracy = etudiant.evaluate(validation_dataset, verbose = 0)\n",
    "        if val_accuracy > val_accuracy_max:\n",
    "            val_accuracy_max = val_accuracy\n",
    "            etudiant.save(f\"sauvegardes/{nom_modele}_checkpoint.keras\")\n",
    "        else:\n",
    "            adam.learning_rate.assign(adam.learning_rate.numpy() * 0.8)\n",
    "        append_csv_log(f\"sauvegardes/{nom_modele}_logs.csv\", epoch, accuracy, val_accuracy)\n",
    "        print(f\"Accuracy (train) : {accuracy:.4f} | Accuracy (val) : {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_resnet18(temp, alpha):\n",
    "    tf.keras.backend.clear_session()\n",
    "    modele = new_modele_resnet()\n",
    "    nom_modele =  f\"model_etudiant_t{temp:d}_a{int(alpha*100):d}\"\n",
    "    distillateur_kl(modele, model_enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch,0.25)\n",
    "    wd = os.getcwd()\n",
    "    os.system(f\"cp {wd}/sauvegardes/{nom_modele}_checkpoint.keras {wd}/sauvegardes/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}.keras s3/afeldmann/projet_cnam/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}_logs.csv s3/afeldmann/projet_cnam/{nom_modele}_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/qubvel/classification_models/releases/download/0.0.1/resnet18_imagenet_1000_no_top.h5\n",
      "\u001b[1m44920640/44920640\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "C'est parti pour la distillation !\n",
      "\n",
      "Époque 1 / 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 07:20:49.573939: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m440s\u001b[0m 529ms/step - acc: 0.1274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713079709.476407     499 service.cc:145] XLA service 0x7f8f8801ce70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713079709.477075     499 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-04-14 07:28:29.590843: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1713079715.984703     499 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) : 0.1274 | Accuracy (val) : 0.0906\n",
      "Époque 2 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m372s\u001b[0m 529ms/step - acc: 0.2682\n",
      "Accuracy (train) : 0.2682 | Accuracy (val) : 0.2848\n",
      "Époque 3 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 574ms/step - acc: 0.3493\n",
      "Accuracy (train) : 0.3493 | Accuracy (val) : 0.3452\n",
      "Époque 4 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 610ms/step - acc: 0.4071\n",
      "Accuracy (train) : 0.4071 | Accuracy (val) : 0.3912\n",
      "Époque 5 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 570ms/step - acc: 0.4442\n",
      "Accuracy (train) : 0.4442 | Accuracy (val) : 0.4294\n",
      "Époque 6 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 603ms/step - acc: 0.4709\n",
      "Accuracy (train) : 0.4709 | Accuracy (val) : 0.4556\n",
      "Époque 7 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 593ms/step - acc: 0.4921\n",
      "Accuracy (train) : 0.4921 | Accuracy (val) : 0.4596\n",
      "Époque 8 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m423s\u001b[0m 602ms/step - acc: 0.5160\n",
      "Accuracy (train) : 0.5160 | Accuracy (val) : 0.4298\n",
      "Époque 9 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 596ms/step - acc: 0.5510\n",
      "Accuracy (train) : 0.5510 | Accuracy (val) : 0.4942\n",
      "Époque 10 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 596ms/step - acc: 0.5658\n",
      "Accuracy (train) : 0.5658 | Accuracy (val) : 0.4980\n",
      "Époque 11 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 583ms/step - acc: 0.5765\n",
      "Accuracy (train) : 0.5765 | Accuracy (val) : 0.4998\n",
      "Époque 12 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 595ms/step - acc: 0.5908\n",
      "Accuracy (train) : 0.5908 | Accuracy (val) : 0.5314\n",
      "Époque 13 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 608ms/step - acc: 0.6053\n",
      "Accuracy (train) : 0.6053 | Accuracy (val) : 0.5346\n",
      "Époque 14 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 583ms/step - acc: 0.6152\n",
      "Accuracy (train) : 0.6152 | Accuracy (val) : 0.5388\n",
      "Époque 15 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 583ms/step - acc: 0.6240\n",
      "Accuracy (train) : 0.6240 | Accuracy (val) : 0.5530\n",
      "Époque 16 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m434s\u001b[0m 617ms/step - acc: 0.6311\n",
      "Accuracy (train) : 0.6311 | Accuracy (val) : 0.5442\n",
      "Époque 17 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 586ms/step - acc: 0.6510\n",
      "Accuracy (train) : 0.6510 | Accuracy (val) : 0.5756\n",
      "Époque 18 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 616ms/step - acc: 0.6622\n",
      "Accuracy (train) : 0.6622 | Accuracy (val) : 0.5688\n",
      "Époque 19 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 584ms/step - acc: 0.6805\n",
      "Accuracy (train) : 0.6805 | Accuracy (val) : 0.5928\n",
      "Époque 20 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 584ms/step - acc: 0.6915\n",
      "Accuracy (train) : 0.6915 | Accuracy (val) : 0.5928\n",
      "Époque 21 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m420s\u001b[0m 598ms/step - acc: 0.7038\n",
      "Accuracy (train) : 0.7038 | Accuracy (val) : 0.5960\n",
      "Époque 22 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m413s\u001b[0m 588ms/step - acc: 0.7087\n",
      "Accuracy (train) : 0.7087 | Accuracy (val) : 0.6034\n",
      "Époque 23 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 584ms/step - acc: 0.7144\n",
      "Accuracy (train) : 0.7144 | Accuracy (val) : 0.5966\n",
      "Époque 24 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m422s\u001b[0m 601ms/step - acc: 0.7268\n",
      "Accuracy (train) : 0.7268 | Accuracy (val) : 0.6134\n",
      "Époque 25 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 610ms/step - acc: 0.7316\n",
      "Accuracy (train) : 0.7316 | Accuracy (val) : 0.6082\n",
      "Époque 26 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 573ms/step - acc: 0.7435\n",
      "Accuracy (train) : 0.7435 | Accuracy (val) : 0.6120\n",
      "Époque 27 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 611ms/step - acc: 0.7498\n",
      "Accuracy (train) : 0.7498 | Accuracy (val) : 0.6302\n",
      "Époque 28 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 585ms/step - acc: 0.7562\n",
      "Accuracy (train) : 0.7562 | Accuracy (val) : 0.6268\n",
      "Époque 29 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 592ms/step - acc: 0.7628\n",
      "Accuracy (train) : 0.7628 | Accuracy (val) : 0.6296\n",
      "Époque 30 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 606ms/step - acc: 0.7641\n",
      "Accuracy (train) : 0.7641 | Accuracy (val) : 0.6352\n",
      "Époque 31 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 584ms/step - acc: 0.7673\n",
      "Accuracy (train) : 0.7673 | Accuracy (val) : 0.6364\n",
      "Époque 32 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 590ms/step - acc: 0.7735\n",
      "Accuracy (train) : 0.7735 | Accuracy (val) : 0.6382\n",
      "Époque 33 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 611ms/step - acc: 0.7750\n",
      "Accuracy (train) : 0.7750 | Accuracy (val) : 0.6386\n",
      "Époque 34 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 613ms/step - acc: 0.7757\n",
      "Accuracy (train) : 0.7757 | Accuracy (val) : 0.6484\n",
      "Époque 35 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m418s\u001b[0m 594ms/step - acc: 0.7815\n",
      "Accuracy (train) : 0.7815 | Accuracy (val) : 0.6452\n",
      "Époque 36 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m435s\u001b[0m 619ms/step - acc: 0.7869\n",
      "Accuracy (train) : 0.7869 | Accuracy (val) : 0.6444\n",
      "Époque 37 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m443s\u001b[0m 631ms/step - acc: 0.7855\n",
      "Accuracy (train) : 0.7855 | Accuracy (val) : 0.6458\n",
      "Époque 38 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m421s\u001b[0m 599ms/step - acc: 0.7881\n",
      "Accuracy (train) : 0.7881 | Accuracy (val) : 0.6570\n",
      "Époque 39 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m432s\u001b[0m 615ms/step - acc: 0.7937\n",
      "Accuracy (train) : 0.7937 | Accuracy (val) : 0.6560\n",
      "Époque 40 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 607ms/step - acc: 0.7934\n",
      "Accuracy (train) : 0.7934 | Accuracy (val) : 0.6578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-14 12:06:43.900373: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: RecvAsync is cancelled.\n",
      "\t [[{{node GroupCrossDeviceControlEdges_0/NoOp/_45}}]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "2024-04-14 12:06:43.900556: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: RecvAsync is cancelled.\n",
      "\t [[{{node GroupCrossDeviceControlEdges_0/NoOp/_45}}]]\n",
      "\t [[sequential_1_1/random_translation_1/add_1/_42]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "2024-04-14 12:06:43.900630: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 7564607746336802277\n",
      "2024-04-14 12:06:43.900694: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: RecvAsync is cancelled.\n",
      "\t [[{{node sequential_1_1/random_rotation_1/add/_32}}]] [type.googleapis.com/tensorflow.DerivedStatus='']\n",
      "2024-04-14 12:06:43.900725: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3867752498272519620\n",
      "2024-04-14 12:06:43.900739: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 16130924311928198926\n",
      "2024-04-14 12:06:43.900754: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 5343937524244023778\n",
      "2024-04-14 12:06:43.900779: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12005179445966797404\n",
      "2024-04-14 12:06:43.900793: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 11613945291462794484\n",
      "2024-04-14 12:06:43.900820: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 9202690463507869196\n",
      "2024-04-14 12:06:43.900837: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 10754741183566029003\n",
      "2024-04-14 12:06:43.900862: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17875514257345720661\n",
      "2024-04-14 12:06:43.900877: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 13772814494580941399\n",
      "2024-04-14 12:06:43.900894: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 11023024491552748533\n",
      "2024-04-14 12:06:43.900920: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 7564607746336802277\n",
      "2024-04-14 12:06:43.900939: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 9947950212527517801\n",
      "2024-04-14 12:06:43.900979: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 17968683270078605203\n",
      "2024-04-14 12:06:43.901012: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 10876457619563247667\n",
      "2024-04-14 12:06:43.901027: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 17446752615187581027\n",
      "2024-04-14 12:06:43.901058: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 15858561958036035659\n",
      "2024-04-14 12:06:43.901071: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 11653823692689539729\n",
      "2024-04-14 12:06:43.901083: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 8927492369313161131\n",
      "2024-04-14 12:06:44.198564: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: CANCELLED: RecvAsync is cancelled.\n",
      "\t [[{{node sequential_1_1/random_rotation_1/add/_32}}]]\n",
      "\t [[sequential_1_1/random_brightness_1/ReadVariableOp_1/_4]] [type.googleapis.com/tensorflow.DerivedStatus='']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_t1_a100.keras` -> `s3/afeldmann/projet_cnam/model_etudiant_t1_a100.keras`\n",
      "Total: 43.54 MiB, Transferred: 43.54 MiB, Speed: 106.25 MiB/s\n",
      "`/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_t1_a100_logs.csv` -> `s3/afeldmann/projet_cnam/model_etudiant_t1_a100_logs.csv`\n",
      "Total: 539 B, Transferred: 539 B, Speed: 4.00 KiB/s\n"
     ]
    }
   ],
   "source": [
    "distillation_resnet18(1,1) # témoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est parti pour la distillation !\n",
      "\n",
      "Époque 1 / 40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/tmp/ipykernel_225/4231580846.py\", line 37, in forward_backward_pass  *\n        adam.apply_gradients(zip(grads, etudiant_logit_model.trainable_variables))\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 308, in apply\n        self.build(trainable_variables)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 93, in build\n        self.add_variable_from_reference(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 34, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 205, in add_variable_from_reference\n        return self.add_variable(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 184, in add_variable\n        variable = backend.Variable(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/common/variables.py\", line 80, in __init__\n        self._initialize(value)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py\", line 30, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdistillation_resnet18\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 5\u001b[0m, in \u001b[0;36mdistillation_resnet18\u001b[0;34m(temp, alpha)\u001b[0m\n\u001b[1;32m      3\u001b[0m modele \u001b[38;5;241m=\u001b[39m new_modele_resnet()\n\u001b[1;32m      4\u001b[0m nom_modele \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_etudiant_t\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtemp\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_a\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mint\u001b[39m(alpha\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mdistillateur_kl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodele\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_enseignant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnom_modele\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m wd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m      7\u001b[0m os\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcp \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sauvegardes/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnom_modele\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_checkpoint.keras \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwd\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/sauvegardes/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnom_modele\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 58\u001b[0m, in \u001b[0;36mdistillateur_kl\u001b[0;34m(etudiant, enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch, alpha)\u001b[0m\n\u001b[1;32m     56\u001b[0m bons_epoque \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_batch):\n\u001b[0;32m---> 58\u001b[0m     bons_epoque \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mforward_backward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metudiant_logit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     59\u001b[0m     accuracy \u001b[38;5;241m=\u001b[39m bons_epoque \u001b[38;5;241m/\u001b[39m ((i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m batch_size)\n\u001b[1;32m     60\u001b[0m     barre_progression\u001b[38;5;241m.\u001b[39mupdate(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, values \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)])\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_filedwi0n6iu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__forward_backward_pass\u001b[0;34m(train_dataset_iter, etudiant_logit_model, alpha, temp, adam)\u001b[0m\n\u001b[1;32m     13\u001b[0m     perte \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(alpha) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(softmax_cross_entropy_with_logits), (ag__\u001b[38;5;241m.\u001b[39mld(y_batch), ag__\u001b[38;5;241m.\u001b[39mld(etudiant_estim_logit)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope) \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m ag__\u001b[38;5;241m.\u001b[39mld(alpha)) \u001b[38;5;241m*\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(ce), (ag__\u001b[38;5;241m.\u001b[39mld(enseignant_estim_softmax), ag__\u001b[38;5;241m.\u001b[39mld(etudiant_estim_logit), ag__\u001b[38;5;241m.\u001b[39mld(temp)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m grads \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(tape)\u001b[38;5;241m.\u001b[39mgradient, (ag__\u001b[38;5;241m.\u001b[39mld(perte), ag__\u001b[38;5;241m.\u001b[39mld(etudiant_logit_model)\u001b[38;5;241m.\u001b[39mtrainable_variables), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 15\u001b[0m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43madam\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43metudiant_logit_model\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:269\u001b[0m, in \u001b[0;36mBaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads_and_vars):\n\u001b[1;32m    268\u001b[0m     grads, trainable_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;66;03m# Return iterations for compat with tf.keras.\u001b[39;00m\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterations\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:308\u001b[0m, in \u001b[0;36mBaseOptimizer.apply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 308\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_variables_are_known(trainable_variables)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/adam.py:93\u001b[0m, in \u001b[0;36mAdam.build\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m var_list:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_momentums\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m---> 93\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     )\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_velocities\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_variable_from_reference(\n\u001b[1;32m     99\u001b[0m             reference_variable\u001b[38;5;241m=\u001b[39mvar, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvelocity\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m         )\n\u001b[1;32m    101\u001b[0m     )\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mamsgrad:\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py:34\u001b[0m, in \u001b[0;36mTFOptimizer.add_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m     29\u001b[0m     colocate_var \u001b[38;5;241m=\u001b[39m reference_variable\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_distribution_strategy\u001b[38;5;241m.\u001b[39mextended\u001b[38;5;241m.\u001b[39mcolocate_vars_with(\n\u001b[1;32m     32\u001b[0m     colocate_var\n\u001b[1;32m     33\u001b[0m ):\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable_from_reference\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference_variable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:205\u001b[0m, in \u001b[0;36mBaseOptimizer.add_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(reference_variable\u001b[38;5;241m.\u001b[39mname)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_variable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference_variable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:184\u001b[0m, in \u001b[0;36mBaseOptimizer.add_variable\u001b[0;34m(self, shape, initializer, dtype, name)\u001b[0m\n\u001b[1;32m    182\u001b[0m initializer \u001b[38;5;241m=\u001b[39m initializers\u001b[38;5;241m.\u001b[39mget(initializer)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, caller\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 184\u001b[0m     variable \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43minitializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_track_variable(variable)\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m variable\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/backend/common/variables.py:80\u001b[0m, in \u001b[0;36mKerasVariable.__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, name)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         value \u001b[38;5;241m=\u001b[39m initializer\n\u001b[0;32m---> 80\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_initialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape)\n",
      "File \u001b[0;32m/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py:30\u001b[0m, in \u001b[0;36mVariable._initialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_initialize\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mVariable\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/tmp/ipykernel_225/4231580846.py\", line 37, in forward_backward_pass  *\n        adam.apply_gradients(zip(grads, etudiant_logit_model.trainable_variables))\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 269, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 308, in apply\n        self.build(trainable_variables)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 93, in build\n        self.add_variable_from_reference(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 34, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 205, in add_variable_from_reference\n        return self.add_variable(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 184, in add_variable\n        variable = backend.Variable(\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/common/variables.py\", line 80, in __init__\n        self._initialize(value)\n    File \"/opt/mamba/lib/python3.11/site-packages/keras/src/backend/tensorflow/core.py\", line 30, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
     ]
    }
   ],
   "source": [
    "distillation_resnet18(1,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(3,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(8,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(8,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphiques_accuracy(temp, alpha):\n",
    "    nom_modele =  f\"model_etudiant_t{temp:d}_a{int(alpha*100):d}\"\n",
    "    history=np.genfromtxt(f\"sauvegardes/{nom_modele}_logs.csv\", delimiter=\",\", names = True)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Modèle enseignant')\n",
    "    plt.ylabel('Exactitude')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.axvline(x=47, color='purple', ls='--', lw=2, label='Limite réglage fin')\n",
    "    plt.legend(['Entrainement', 'Validation','Limite réglage fin'], loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9bONC3xH3xaW7dDlmJISS",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "106xzOLKiTWG5i8p3_sRoYD7Xjz-gmRDB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
