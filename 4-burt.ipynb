{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b2dc38-c62f-48b4-b184-52bef5d5b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: image_classifiers in /opt/mamba/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/mamba/lib/python3.12/site-packages (from image_classifiers) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/mamba/lib/python3.12/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (1.26.4)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.12/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.11.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 14:07:20.751632: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-03 14:07:20.752439: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-03 14:07:20.758219: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-03 14:07:20.820257: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-03 14:07:21.800469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install image_classifiers\n",
    "#!pip install keras==3.1.1 tensorflow==2.16.1\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import ResNet50V2\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Model\n",
    "from classification_models.keras import Classifiers\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0274a3c8-8173-46dd-9c24-f16796079a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 100\n",
    "n_images_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477db83a-808e-4817-a53b-9ccb9cdba1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 55.63 MiB/s 2s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.1.1 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cc10e5-0ac4-4557-a1f8-aa16580e7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef993be-6979-40f6-9083-d86d17451318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1_a0.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 50.91 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t1_a0.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_distille.keras\n",
    "model_etudiant_distille = new_modele_resnet()\n",
    "model_etudiant_distille.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_distille.keras\")\n",
    "model_etudiant_distille.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a45af9-5d73-4cee-9966-ed3482f19da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a100.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 51.75 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t1_a100.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_temoin.keras\n",
    "model_etudiant_temoin = new_modele_resnet()\n",
    "model_etudiant_temoin.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_temoin.keras\")\n",
    "model_etudiant_temoin.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309eb8e8-0dc7-4f69-995f-d251de46a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def load_cifar_test():\n",
    "    _, test_dataset = cifar100.load_data()\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing, num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size).map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25123768-589d-48a8-b873-64990eb7722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def argmax_equals(x,y):\n",
    "    return tf.equal(tf.argmax(x, axis = 1), tf.argmax(y, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aceeaa7-7973-4d98-8897-28ae4876d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_cifar_test()\n",
    "\n",
    "@tf.function\n",
    "def make_burt(images, label):\n",
    "    enseignant_pred = model_enseignant(images, training = False)\n",
    "    etudiant_temoin_pred = model_etudiant_temoin(images, training = False)\n",
    "    etudiant_distille_pred = model_etudiant_distille(images, training = False)\n",
    "    bons_enseignant = argmax_equals(enseignant_pred,label)\n",
    "    bons_etudiant_temoin = argmax_equals(etudiant_temoin_pred, label)\n",
    "    bons_etudiant_distille = argmax_equals(etudiant_distille_pred, label)\n",
    "    tdc = tf.cast(\n",
    "        tf.stack([bons_enseignant,\n",
    "                  tf.math.logical_not(bons_enseignant),\n",
    "                  bons_etudiant_temoin,\n",
    "                  tf.math.logical_not(bons_etudiant_temoin),\n",
    "                  bons_etudiant_distille,\n",
    "                  tf.math.logical_not(bons_etudiant_distille)],\n",
    "                  axis=1),\n",
    "        tf.int32)\n",
    "    burt = tf.linalg.matmul(tf.transpose(tdc),tdc)\n",
    "    return burt\n",
    "\n",
    "burt = test_dataset.map(make_burt, num_parallel_calls = tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).reduce(0, lambda x, y: x + y).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abca4e84-3474-46a6-9e6e-bf3221140199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7651,    0, 6309, 1342, 6331, 1320],\n",
       "       [   0, 2349,  765, 1584,  671, 1678],\n",
       "       [6309,  765, 7074,    0, 6092,  982],\n",
       "       [1342, 1584,    0, 2926,  910, 2016],\n",
       "       [6331,  671, 6092,  910, 7002,    0],\n",
       "       [1320, 1678,  982, 2016,    0, 2998]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01495841-325a-4ec2-b97b-861668fd846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100. ,   0. ,  82.5,  17.5,  82.7,  17.3],\n",
       "       [  0. , 100. ,  32.6,  67.4,  28.6,  71.4],\n",
       "       [ 89.2,  10.8, 100. ,   0. ,  86.1,  13.9],\n",
       "       [ 45.9,  54.1,   0. , 100. ,  31.1,  68.9],\n",
       "       [ 90.4,   9.6,  87. ,  13. , 100. ,   0. ],\n",
       "       [ 44. ,  56. ,  32.8,  67.2,   0. , 100. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burt_lignes = np.apply_along_axis(lambda x: np.round(x/x.sum()*300, 1), 1, burt)\n",
    "burt_lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6198bfdd-cb8f-41af-b8df-e0caae52cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...lignes.csv: 900 B / 900 B ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 10.97 KiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b]11;?\u001b\\\u001b[6n\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"sauvegardes/burt.csv\", burt, delimiter = \",\")\n",
    "np.savetxt(\"sauvegardes/burt_lignes.csv\", burt_lignes, delimiter = \",\")\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/burt.csv s3/afeldmann/projet_cnam/burt.csv\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/burt_lignes.csv s3/afeldmann/projet_cnam/burt_lignes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5f82db-3669-430c-afcd-cc1e1158bb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 14:10:04.086085: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "/tmp/ipykernel_5668/690759924.py:36: RuntimeWarning: invalid value encountered in divide\n",
      "  burt_probas = [i.numpy() / burt for i in burt_probas_sum]\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def get_probas(bons_enseignant, bons_etudiant_temoin, bons_etudiant_distille, preds):\n",
    "    max_preds = tf.math.reduce_max(preds, axis = 1)\n",
    "    tdc = tf.cast(\n",
    "        tf.stack([bons_enseignant,\n",
    "                  tf.math.logical_not(bons_enseignant),\n",
    "                  bons_etudiant_temoin,\n",
    "                  tf.math.logical_not(bons_etudiant_temoin),\n",
    "                  bons_etudiant_distille,\n",
    "                  tf.math.logical_not(bons_etudiant_distille)],\n",
    "                  axis=1),\n",
    "        tf.float32)\n",
    "    burt_probas = tf.linalg.matmul(tf.transpose(tdc) * max_preds, tdc)\n",
    "    return burt_probas\n",
    "\n",
    "@tf.function\n",
    "def make_probas(images, label):\n",
    "    enseignant_pred = model_enseignant(images, training = False)\n",
    "    etudiant_temoin_pred = model_etudiant_temoin(images, training = False)\n",
    "    etudiant_distille_pred = model_etudiant_distille(images, training = False)\n",
    "    bons_enseignant = argmax_equals(enseignant_pred,label)\n",
    "    bons_etudiant_temoin = argmax_equals(etudiant_temoin_pred, label)\n",
    "    bons_etudiant_distille = argmax_equals(etudiant_distille_pred, label)\n",
    "    burt_probas_enseignant = get_probas(bons_enseignant, bons_etudiant_temoin, bons_etudiant_distille, enseignant_pred)\n",
    "    burt_probas_etudiant_temoin_pred = get_probas(bons_enseignant, bons_etudiant_temoin, bons_etudiant_distille, etudiant_temoin_pred)\n",
    "    burt_probas_etudiant_distille = get_probas(bons_enseignant, bons_etudiant_temoin, bons_etudiant_distille, etudiant_distille_pred)\n",
    "    return burt_probas_enseignant, burt_probas_etudiant_temoin_pred, burt_probas_etudiant_distille\n",
    "\n",
    "burt_probas_sum = (\n",
    "    test_dataset\n",
    "    .map(make_probas, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    "    .reduce((tf.constant(0.0,shape=burt.shape),)*3, lambda x, y: (x[0] + y[0], x[1] + y[1], x[2] + y[2]))\n",
    ")\n",
    "\n",
    "burt_probas = [i.numpy() / burt for i in burt_probas_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd5a2803-7be3-451c-93fb-d1c762e57ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...probas.csv: 474 B / 474 B ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 5.20 KiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "burt_probas_en_forme = [[f\"{burt_probas[0][i, j]*100:.0f} | {burt_probas[1][i, j]*100:.0f} | {burt_probas[2][i, j]*100:.0f}\" for j in range(burt_probas[0].shape[1])] for i in range(burt_probas[0].shape[0])]\n",
    "np.savetxt(\"sauvegardes/burt_probas.csv\", burt_probas_en_forme, fmt = \"%s\", delimiter = \";\")\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/burt_probas.csv s3/afeldmann/projet_cnam/burt_probas.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a9496e3-27b5-4950-b6dc-6421de514d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.88465286,        nan, 0.91609836, 0.73682118, 0.91825242,\n",
       "         0.72350274],\n",
       "        [       nan, 0.56961479, 0.57969624, 0.56474597, 0.57058134,\n",
       "         0.56922827],\n",
       "        [0.91609836, 0.57969624, 0.87971888,        nan, 0.90770651,\n",
       "         0.7060936 ],\n",
       "        [0.73682118, 0.56474597,        nan, 0.6436677 , 0.73249123,\n",
       "         0.60357375],\n",
       "        [0.91825242, 0.57058134, 0.90770651, 0.73249123, 0.88493487,\n",
       "                nan],\n",
       "        [0.72350274, 0.56922827, 0.7060936 , 0.60357375,        nan,\n",
       "         0.63715438]]),\n",
       " array([[0.27112332,        nan, 0.3077712 , 0.0988345 , 0.30312394,\n",
       "         0.11764131],\n",
       "        [       nan, 0.11674783, 0.14347634, 0.1038392 , 0.13914549,\n",
       "         0.10779145],\n",
       "        [0.3077712 , 0.14347634, 0.29000389,        nan, 0.31567543,\n",
       "         0.13074661],\n",
       "        [0.0988345 , 0.1038392 ,        nan, 0.10154379, 0.09818653,\n",
       "         0.10305928],\n",
       "        [0.30312394, 0.13914549, 0.31567543, 0.09818653, 0.28740988,\n",
       "                nan],\n",
       "        [0.11764131, 0.10779145, 0.13074661, 0.10305928,        nan,\n",
       "         0.11212829]]),\n",
       " array([[0.23077146,        nan, 0.25898334, 0.09814184, 0.2609886 ,\n",
       "         0.08584371],\n",
       "        [       nan, 0.09689717, 0.10903631, 0.0910345 , 0.11452924,\n",
       "         0.08984645],\n",
       "        [0.25898334, 0.10903631, 0.24276769,        nan, 0.26785318,\n",
       "         0.08714524],\n",
       "        [0.09814184, 0.0910345 ,        nan, 0.09429425, 0.10703913,\n",
       "         0.08854136],\n",
       "        [0.2609886 , 0.11452924, 0.26785318, 0.10703913, 0.24695333,\n",
       "                nan],\n",
       "        [0.08584371, 0.08984645, 0.08714524, 0.08854136,        nan,\n",
       "         0.08808405]])]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burt_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef42ae-ff30-43df-b821-bf400b430ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
