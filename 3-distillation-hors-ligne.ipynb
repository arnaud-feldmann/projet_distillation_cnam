{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0a6T1vnVygY3",
    "outputId": "4340d1d4-8699-449f-e667-21465000fcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: image_classifiers in /opt/mamba/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: tqdm in /opt/mamba/lib/python3.11/site-packages (4.66.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/mamba/lib/python3.11/site-packages (from image_classifiers) (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/mamba/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 20:32:31.867176: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-13 20:32:32.787288: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib image_classifiers tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.applications import ResNet50V2\n",
    "from keras.datasets import cifar100\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, UpSampling2D, Dropout, RandomFlip, RandomTranslation, RandomRotation,RandomBrightness, RandomContrast, RandomZoom, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, CSVLogger, ModelCheckpoint\n",
    "from keras.applications.resnet_v2 import preprocess_input\n",
    "from keras.models import Model\n",
    "from classification_models.keras import Classifiers\n",
    "from keras.optimizers import Adam\n",
    "from keras.activations import linear\n",
    "from tqdm.notebook import tqdm\n",
    "from keras.utils import Progbar\n",
    "from tensorflow.nn import softmax_cross_entropy_with_logits\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HJBnQzTj-I-v"
   },
   "outputs": [],
   "source": [
    "n_epoch = 40\n",
    "batch_size = 64\n",
    "taux_validation = 0.1\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 138.79 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 20:32:40.618830: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13775 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.0 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "MLyUvI1U-J0N"
   },
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "augmentation_donnees_keras = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.2,0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2,value_range=(0,1))\n",
    "])\n",
    "\n",
    "def augmentation_donnees(image, label):\n",
    "    return augmentation_donnees_keras(image/255.0, training = True)*255.0, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def train_val_split(train_dataset, validation_size):\n",
    "    X_train, y_train = train_dataset\n",
    "    indices = np.random.permutation(X_train.shape[0])\n",
    "    train_idx, val_idx = indices[:train_size], indices[train_size:]\n",
    "    return (X_train[train_idx,...], y_train[train_idx,...]), (X_train[val_idx,...], y_train[val_idx,...])\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "\n",
    "validation_size = int(n_images * taux_validation)\n",
    "train_size = n_images - validation_size\n",
    "\n",
    "train_dataset, validation_dataset = train_val_split(train_dataset, validation_size)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices(validation_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet).cache().prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).map(preprocessing).cache().repeat().shuffle(train_size).batch(batch_size).map(augmentation_donnees, num_parallel_calls = tf.data.AUTOTUNE).map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "editable": true,
    "id": "g_WFfeF--Sz2",
    "outputId": "11ccfa14-574a-47d3-9483-253c6e0b708a",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_modele_logits(modele):\n",
    "    config = modele.layers[-1].get_config()\n",
    "    config['activation'] = linear\n",
    "    config['name'] = 'logits'\n",
    "    res = Model(inputs=modele.inputs, outputs=[Dense(**config)(modele.layers[-2].output)])\n",
    "    res.layers[-1].set_weights([x.numpy() for x in modele.layers[-1].weights])\n",
    "    res.compile(metrics=['accuracy'])\n",
    "    return res\n",
    "\n",
    "@tf.function\n",
    "def compte_bons(x,y):\n",
    "    return tf.reduce_sum(tf.cast(tf.equal(tf.argmax(x, axis = 1), tf.argmax(y, axis = 1)), tf.float32))\n",
    "\n",
    "@tf.function\n",
    "def softmax(logits, temp):\n",
    "    expo = tf.exp(logits / temp)\n",
    "    return expo / tf.reduce_sum(expo, axis = 1, keepdims=True)\n",
    "\n",
    "@tf.function\n",
    "def ce(x, y_logits, temp):\n",
    "    return softmax_cross_entropy_with_logits(x, y_logits / temp) * temp**2\n",
    "\n",
    "def init_csv_log(fichier):\n",
    "    with open(fichier,'w') as file:\n",
    "        file.write(\"epoch, accuracy,val_accuracy\\n\")\n",
    "def append_csv_log(fichier, epoch, accuracy,val_accuracy):\n",
    "    with open(fichier,'a') as file:\n",
    "        file.write(f\"{epoch:d},{accuracy:.2f},{val_accuracy:.2f}\\n\")\n",
    "\n",
    "@tf.function\n",
    "def forward_backward_pass(train_dataset_iter, etudiant_logit_model, alpha, temp, adam):\n",
    "    X_batch, y_batch, enseignant_estim_softmax = next(train_dataset_iter)\n",
    "    with tf.GradientTape() as tape:\n",
    "        etudiant_estim_logit = etudiant_logit_model(X_batch, training = True)\n",
    "        perte = alpha * softmax_cross_entropy_with_logits(y_batch,etudiant_estim_logit) + (1-alpha) * ce(enseignant_estim_softmax,etudiant_estim_logit, temp)\n",
    "    grads = tape.gradient(perte, etudiant_logit_model.trainable_variables)\n",
    "    adam.apply_gradients(zip(grads, etudiant_logit_model.trainable_variables))\n",
    "    return compte_bons(etudiant_estim_logit,y_batch)\n",
    "\n",
    "def distillateur_kl(etudiant, enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch, alpha):\n",
    "    etudiant_logit_model = get_modele_logits(etudiant)\n",
    "    enseignant_logit_model = get_modele_logits(enseignant)\n",
    "    adam = Adam(learning_rate=0.001)\n",
    "    init_csv_log(f\"sauvegardes/{nom_modele}_logs.csv\")\n",
    "    print(\"C'est parti pour la distillation !\\n\")\n",
    "    val_accuracy_max = 0\n",
    "    train_dataset_iter = iter(\n",
    "        train_dataset\n",
    "        .map(lambda images, label: (images, label, softmax(enseignant_logit_model(images, training = False), temp)), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "        .prefetch(tf.data.AUTOTUNE)\n",
    "    )\n",
    "    for epoch in range(n_epoch):\n",
    "        print(f\"Époque {epoch + 1} / {n_epoch}\")\n",
    "        n_batch = train_size//batch_size\n",
    "        barre_progression = Progbar(n_batch, stateful_metrics = [\"acc\"])\n",
    "        bons_epoque = 0\n",
    "        for i in range(n_batch):\n",
    "            bons_epoque += forward_backward_pass(train_dataset_iter, etudiant_logit_model, alpha, temp, adam).numpy()\n",
    "            accuracy = bons_epoque / ((i+1) * batch_size)\n",
    "            barre_progression.update(i + 1, values = [(\"acc\", accuracy)])\n",
    "        _, val_accuracy = etudiant.evaluate(validation_dataset, verbose = 0)\n",
    "        if val_accuracy > val_accuracy_max:\n",
    "            val_accuracy_max = val_accuracy\n",
    "            etudiant.save(f\"sauvegardes/{nom_modele}_checkpoint.keras\")\n",
    "        else:\n",
    "            adam.learning_rate.assign(adam.learning_rate.numpy() * 0.8)\n",
    "        append_csv_log(f\"sauvegardes/{nom_modele}_logs.csv\", epoch, accuracy, val_accuracy)\n",
    "        print(f\"Accuracy (train) : {accuracy:.4f} | Accuracy (val) : {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distillation_resnet18(temp, alpha):\n",
    "    tf.keras.backend.clear_session()\n",
    "    modele = new_modele_resnet()\n",
    "    nom_modele =  f\"model_etudiant_t{temp:d}_a{int(alpha*100):d}\"\n",
    "    distillateur_kl(modele, model_enseignant, train_dataset, validation_dataset, temp, nom_modele, n_epoch,0.25)\n",
    "    wd = os.getcwd()\n",
    "    os.system(f\"cp {wd}/sauvegardes/{nom_modele}_checkpoint.keras {wd}/sauvegardes/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}.keras s3/afeldmann/projet_cnam/{nom_modele}.keras\")\n",
    "    os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}_logs.csv s3/afeldmann/projet_cnam/{nom_modele}_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est parti pour la distillation !\n",
      "\n",
      "Époque 1 / 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 20:33:23.615113: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m449s\u001b[0m 588ms/step - acc: 0.1328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713040863.675378   20451 service.cc:145] XLA service 0x7f5e2c018be0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713040863.675495   20451 service.cc:153]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "2024-04-13 20:41:03.783737: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1713040870.172090   20451 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (train) : 0.1328 | Accuracy (val) : 0.0642\n",
      "Époque 2 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m367s\u001b[0m 523ms/step - acc: 0.2754\n",
      "Accuracy (train) : 0.2754 | Accuracy (val) : 0.2554\n",
      "Époque 3 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 563ms/step - acc: 0.3521\n",
      "Accuracy (train) : 0.3521 | Accuracy (val) : 0.3200\n",
      "Époque 4 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 573ms/step - acc: 0.4034\n",
      "Accuracy (train) : 0.4034 | Accuracy (val) : 0.3828\n",
      "Époque 5 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 572ms/step - acc: 0.4424\n",
      "Accuracy (train) : 0.4424 | Accuracy (val) : 0.4328\n",
      "Époque 6 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m404s\u001b[0m 575ms/step - acc: 0.4737\n",
      "Accuracy (train) : 0.4737 | Accuracy (val) : 0.4456\n",
      "Époque 7 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 564ms/step - acc: 0.4954\n",
      "Accuracy (train) : 0.4954 | Accuracy (val) : 0.4196\n",
      "Époque 8 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m399s\u001b[0m 568ms/step - acc: 0.5315\n",
      "Accuracy (train) : 0.5315 | Accuracy (val) : 0.4922\n",
      "Époque 9 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 581ms/step - acc: 0.5475\n",
      "Accuracy (train) : 0.5475 | Accuracy (val) : 0.4986\n",
      "Époque 10 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 585ms/step - acc: 0.5648\n",
      "Accuracy (train) : 0.5648 | Accuracy (val) : 0.4810\n",
      "Époque 11 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m403s\u001b[0m 574ms/step - acc: 0.5853\n",
      "Accuracy (train) : 0.5853 | Accuracy (val) : 0.5454\n",
      "Époque 12 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 562ms/step - acc: 0.6030\n",
      "Accuracy (train) : 0.6030 | Accuracy (val) : 0.5258\n",
      "Époque 13 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m402s\u001b[0m 572ms/step - acc: 0.6246\n",
      "Accuracy (train) : 0.6246 | Accuracy (val) : 0.5680\n",
      "Époque 14 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 566ms/step - acc: 0.6328\n",
      "Accuracy (train) : 0.6328 | Accuracy (val) : 0.5676\n",
      "Époque 15 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 566ms/step - acc: 0.6489\n",
      "Accuracy (train) : 0.6489 | Accuracy (val) : 0.5782\n",
      "Époque 16 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 570ms/step - acc: 0.6636\n",
      "Accuracy (train) : 0.6636 | Accuracy (val) : 0.5830\n",
      "Époque 17 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 556ms/step - acc: 0.6720\n",
      "Accuracy (train) : 0.6720 | Accuracy (val) : 0.5992\n",
      "Époque 18 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m410s\u001b[0m 583ms/step - acc: 0.6767\n",
      "Accuracy (train) : 0.6767 | Accuracy (val) : 0.5906\n",
      "Époque 19 / 40\n",
      "\u001b[1m703/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 564ms/step - acc: 0.6889\n",
      "Accuracy (train) : 0.6889 | Accuracy (val) : 0.6048\n",
      "Époque 20 / 40\n",
      "\u001b[1m669/703\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m19s\u001b[0m 584ms/step - acc: 0.6949"
     ]
    }
   ],
   "source": [
    "distillation_resnet18(1,1) # témoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(1,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(3,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(8,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(3,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distillation_resnet18(8,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphiques_accuracy(temp, alpha):\n",
    "    nom_modele =  f\"model_etudiant_t{temp:d}_a{int(alpha*100):d}\"\n",
    "    history=np.genfromtxt(f\"sauvegardes/{nom_modele}_logs.csv\", delimiter=\",\", names = True)\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.title('Modèle enseignant')\n",
    "    plt.ylabel('Exactitude')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.axvline(x=47, color='purple', ls='--', lw=2, label='Limite réglage fin')\n",
    "    plt.legend(['Entrainement', 'Validation','Limite réglage fin'], loc='best')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM9bONC3xH3xaW7dDlmJISS",
   "gpuType": "A100",
   "include_colab_link": true,
   "machine_shape": "hm",
   "mount_file_id": "106xzOLKiTWG5i8p3_sRoYD7Xjz-gmRDB",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
