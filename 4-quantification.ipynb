{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc8YkE46d5Sk",
    "outputId": "cfd3c208-2b49-47aa-a433-f2ea43363125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras_cv in /usr/local/lib/python3.10/dist-packages (0.8.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_cv) (24.0)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_cv) (1.4.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_cv) (2023.12.25)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from keras_cv) (4.9.4)\n",
      "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.1.7)\n",
      "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_cv) (0.2.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_cv) (4.66.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (1.25.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (13.7.1)\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.0.7)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (3.9.0)\n",
      "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_cv) (0.1.8)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (8.1.7)\n",
      "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.7.0)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (3.20.3)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (5.9.5)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (2.4.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.10.2)\n",
      "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (1.14.1)\n",
      "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->keras_cv) (0.5.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (2023.6.0)\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (6.4.0)\n",
      "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (4.10.0)\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->keras_cv) (3.18.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_cv) (2024.2.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow-datasets->keras_cv) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras-core->keras_cv) (2.16.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv) (1.63.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras_cv) (0.1.2)\n",
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow_model_optimization\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 1000 # Il y a le early stopping\n",
    "batch_size = 100\n",
    "taux_validation = 0.1\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uPDP8KyWfCat"
   },
   "outputs": [],
   "source": [
    "!mc cp s3/afeldmann/modele_enseignant.keras ~/modele_enseignant.keras\n",
    "modele_enseignant = tf.keras.models.load_model(\"~/modele_enseignant.keras\")\n",
    "!mc cp s3/afeldmann/modele_eleve_2.keras ~/modele_eleve_2.keras\n",
    "modele_eleve_2 = tf.keras.models.load_model(\"~/modele_eleve_2.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bd51EjqzvhP7"
   },
   "outputs": [],
   "source": [
    "def format_image(image, label):\n",
    "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "def distillation_hors_ligne(image, label):\n",
    "    label = modele_enseignant.predict(image)\n",
    "    return  image, label\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "\n",
    "validation_size = int(n_images * taux_validation)\n",
    "raw_train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).map(distillation_hors_ligne).shuffle(n_images)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(format_image)\n",
    "\n",
    "validation_dataset = train_dataset.take(validation_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "train_dataset = train_dataset.skip(validation_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cdGtKkxFfcqO",
    "outputId": "83eb68bb-4894-4a34-89f8-ccb7331aa3bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_model_optimization in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
      "Requirement already satisfied: absl-py~=1.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (0.1.8)\n",
      "Requirement already satisfied: numpy~=1.23 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.25.2)\n",
      "Requirement already satisfied: six~=1.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow_model_optimization) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "def apply_pruning_to_dense(layer):\n",
    "  if isinstance(layer, tf.keras.layers.Dense):\n",
    "    return tfmot.sparsity.keras.prune_low_magnitude(layer)\n",
    "  return layer\n",
    "    \n",
    "modele_eleve_2_pruning = tf.keras.models.clone_model(\n",
    "    modele_eleve_2,\n",
    "    clone_function=apply_pruning_to_dense\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-J_5u8eRfTEk",
    "outputId": "e26c949d-715c-4269-bf18-f611e566d0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1563/1563 [==============================] - 23s 10ms/step - loss: 1.9149 - accuracy: 0.3818\n",
      "Epoch 2/2\n",
      "1563/1563 [==============================] - 15s 9ms/step - loss: 1.9066 - accuracy: 0.3845\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7a408c100cd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "modele_eleve_2_pruning.compile(optimizer='adam', loss='kl_divergence', metrics=['accuracy'])\n",
    "\n",
    "modele_eleve_2_pruning.fit(train_dataset, callbacks=callbacks, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IN7Yq5APwYMN",
    "outputId": "d225aa5a-c67e-495e-8cc2-c5e7a6f58894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2239 - accuracy: 0.4159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.223886489868164, 0.41589999198913574]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_eleve_2_pruning.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqDtj1ILunS0",
    "outputId": "38c355c1-9dfc-4978-fd6e-411a81611a14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 2.2239 - accuracy: 0.4159\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.223886489868164, 0.41589999198913574]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modele_eleve_2.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nkO80TA8Di2",
    "outputId": "30f808df-b05d-4b70-87db-66fbc0a80dd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-11ad47b980ba>:4: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: /tmp/tmpfu09hwmk.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(modele_eleve_2_pruning)\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nS6JihkL9dcL",
    "outputId": "664d79e8-36bf-42b5-d68b-88e6c1441de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /content/drive/MyDrive/projet_cnam/modele_prune.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_tflite_model = converter.convert()\n",
    "pruned_tflite_file = \"~/modele_eleve_2_pruning.tflite\"\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-lFfpMf_ncg",
    "outputId": "c8095dae-df05-4214-a4fb-b9b05bed72d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:08<00:00, 115.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions I got 421 correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def format_image_raw(image, label):\n",
    "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
    "    return  image, label\n",
    "\n",
    "test_batches = raw_test.map(format_image_raw).batch(1)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=pruned_tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "test_labels, test_imgs = [], []\n",
    "for img, label in tqdm(test_batches.take(1000)):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "\n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)\n",
    "\n",
    "\n",
    "score = 0\n",
    "for item in range(0,len(predictions)):\n",
    "  prediction=np.argmax(predictions[item])\n",
    "  label = test_labels[item]\n",
    "  if prediction==label:\n",
    "    score=score+1\n",
    "\n",
    "print(\"Out of 1000 predictions I got \" + str(score) + \" correct\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKJ8xfxqA35dOVM+IFKB3Q",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1zfo5zNxKu097eBmdA-BrPQHD7kJFJxRZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
