{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc8YkE46d5Sk",
    "outputId": "cfd3c208-2b49-47aa-a433-f2ea43363125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.11/site-packages (3.8.4)\n",
      "Requirement already satisfied: tensorflow_model_optimization in /opt/mamba/lib/python3.11/site-packages (0.8.0)\n",
      "Requirement already satisfied: tf_keras in /opt/mamba/lib/python3.11/site-packages (2.16.0)\n",
      "Requirement already satisfied: image_classifiers in /opt/mamba/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.11/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: absl-py~=1.2 in /opt/mamba/lib/python3.11/site-packages (from tensorflow_model_optimization) (1.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/mamba/lib/python3.11/site-packages (from tensorflow_model_optimization) (0.1.8)\n",
      "Requirement already satisfied: six~=1.14 in /opt/mamba/lib/python3.11/site-packages (from tensorflow_model_optimization) (1.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /opt/mamba/lib/python3.11/site-packages (from tf_keras) (2.16.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/mamba/lib/python3.11/site-packages (from image_classifiers) (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.10.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (69.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.62.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.1.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/mamba/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.36.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf_keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/mamba/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/mamba/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.0.7)\n",
      "Requirement already satisfied: optree in /opt/mamba/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/mamba/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/mamba/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 18:22:20.034910: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-21 18:22:20.100689: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-21 18:22:21.033483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow_model_optimization tf_keras image_classifiers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "from tf_keras.applications import ResNet50V2\n",
    "from tf_keras.datasets import cifar100\n",
    "from tf_keras import Sequential, Input\n",
    "from tf_keras.layers import Dense, Dropout, RandomFlip, RandomTranslation, RandomRotation,RandomBrightness, RandomContrast, RandomZoom, GlobalAveragePooling2D\n",
    "from tf_keras.applications.resnet_v2 import preprocess_input\n",
    "from tf_keras.models import Model\n",
    "from classification_models.models_factory import ModelsFactory\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModelsFactory(ModelsFactory):\n",
    "    @staticmethod\n",
    "    def get_kwargs():\n",
    "        return {\n",
    "            'backend': keras.backend,\n",
    "            'layers': keras.layers,\n",
    "            'models': keras.models,\n",
    "            'utils': keras.utils,\n",
    "        }\n",
    "# Pour faire marcher image-classifiers avec tf_keras, la version compatibilité de tf.keras, nécéssaire pour tflite\n",
    "Classifiers = KerasModelsFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 100\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uPDP8KyWfCat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 102.12 MiB/s 1s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 18:22:29.050392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13290 MB memory:  -> device: 0, name: NVIDIA A2, pci bus id: 0000:b1:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.1.1 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1_a0.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 96.12 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t1_a0.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant.keras\n",
    "model_etudiant = new_modele_resnet()\n",
    "model_etudiant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant.keras\")\n",
    "model_etudiant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bd51EjqzvhP7"
   },
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "augmentation_donnees_keras = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.2,0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2,value_range=(0,1))\n",
    "])\n",
    "\n",
    "def augmentation_donnees(image, label):\n",
    "    return augmentation_donnees_keras(image/255.0, training = True)*255.0, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_dataset).map(preprocessing).cache().shuffle(n_images).batch(batch_size).map(augmentation_donnees, num_parallel_calls = tf.data.AUTOTUNE).map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing).batch(batch_size).map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_step = np.ceil(n_images / batch_size).astype(np.int32) * n_epoch\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
    "                                                               final_sparsity=0.60,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_etudiant_pruning = tfmot.sparsity.keras.prune_low_magnitude(model_etudiant, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-J_5u8eRfTEk",
    "outputId": "e26c949d-715c-4269-bf18-f611e566d0b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-21 18:23:46.181087: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1713723845.273642   62107 service.cc:145] XLA service 0x7f4d51cb6f60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1713723845.273786   62107 service.cc:153]   StreamExecutor device (0): NVIDIA A2, Compute Capability 8.6\n",
      "I0000 00:00:1713723845.414995   62107 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 328s 507ms/step - loss: 9.2837 - accuracy: 0.6845\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 266s 528ms/step - loss: 8.3904 - accuracy: 0.7168\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 254s 505ms/step - loss: 7.7240 - accuracy: 0.7263\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 251s 499ms/step - loss: 7.1917 - accuracy: 0.7276\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 268s 533ms/step - loss: 6.7698 - accuracy: 0.7250\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 267s 530ms/step - loss: 6.4331 - accuracy: 0.7233\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 266s 528ms/step - loss: 6.1692 - accuracy: 0.7172\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 265s 526ms/step - loss: 5.9525 - accuracy: 0.7187\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 262s 520ms/step - loss: 5.7695 - accuracy: 0.7194\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 266s 529ms/step - loss: 5.6254 - accuracy: 0.7197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f50904e1d90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "model_etudiant_pruning.compile(optimizer=keras.optimizers.SGD(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_etudiant_pruning.fit(train_dataset, callbacks=callbacks, epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 17s 120ms/step - loss: 5.2153 - accuracy: 0.7783\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.215271949768066, 0.7782999873161316]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_etudiant_pruning.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nkO80TA8Di2",
    "outputId": "30f808df-b05d-4b70-87db-66fbc0a80dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_61794/1381957240.py:3: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_etudiant_pruning)\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nS6JihkL9dcL",
    "outputId": "664d79e8-36bf-42b5-d68b-88e6c1441de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp11ff4qp6/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp11ff4qp6/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant.tflite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1713727158.022523   61794 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1713727158.022550   61794 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-04-21 19:19:18.023046: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp11ff4qp6\n",
      "2024-04-21 19:19:18.032863: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-04-21 19:19:18.032880: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp11ff4qp6\n",
      "2024-04-21 19:19:18.100194: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
      "2024-04-21 19:19:18.107817: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-04-21 19:19:18.305235: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /tmp/tmp11ff4qp6\n",
      "2024-04-21 19:19:18.363115: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 340071 microseconds.\n",
      "2024-04-21 19:19:18.445455: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_tflite_model = converter.convert()\n",
    "pruned_tflite_file = \"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant.tflite\"\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-lFfpMf_ncg",
    "outputId": "c8095dae-df05-4214-a4fb-b9b05bed72d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "999it [00:54, 20.39it/s]2024-04-21 19:20:26.822163: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "1000it [00:54, 18.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1000 predictions I got 784 correct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_batches = test_dataset.unbatch().batch(1)\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=pruned_tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "predictions = []\n",
    "\n",
    "test_labels, test_imgs = [], []\n",
    "for img, label in tqdm(test_batches.take(1000)):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    predictions.append(interpreter.get_tensor(output_index))\n",
    "\n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_imgs.append(img)\n",
    "\n",
    "\n",
    "score = 0\n",
    "for item in range(0,len(predictions)):\n",
    "  prediction=np.argmax(predictions[item])\n",
    "  label = np.argmax(test_labels[item])\n",
    "  if prediction==label:\n",
    "    score=score+1\n",
    "\n",
    "print(\"Out of 1000 predictions I got \" + str(score) + \" correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKJ8xfxqA35dOVM+IFKB3Q",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1zfo5zNxKu097eBmdA-BrPQHD7kJFJxRZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
