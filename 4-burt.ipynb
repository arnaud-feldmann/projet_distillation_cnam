{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40b2dc38-c62f-48b4-b184-52bef5d5b8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: image_classifiers in /opt/mamba/lib/python3.11/site-packages (1.0.0)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/mamba/lib/python3.11/site-packages (from image_classifiers) (1.0.8)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (1.26.4)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.11/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.10.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 10:58:10.188418: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-04-28 10:58:10.189413: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-28 10:58:10.196690: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-28 10:58:10.261023: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 10:58:11.368092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install image_classifiers\n",
    "#!pip install keras==3.1.1 tensorflow==2.16.1\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications import ResNet50V2\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras.datasets import cifar100\n",
    "from keras.models import Model\n",
    "from classification_models.keras import Classifiers\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0274a3c8-8173-46dd-9c24-f16796079a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_classes = 100\n",
    "n_images_test = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "477db83a-808e-4817-a53b-9ccb9cdba1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 134.58 MiB/s 1s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = tf.keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = tf.keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.1.1 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5cc10e5-0ac4-4557-a1f8-aa16580e7a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef993be-6979-40f6-9083-d86d17451318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...1_a0.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 106.12 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t1_a0.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_distille.keras\n",
    "model_etudiant_distille = new_modele_resnet()\n",
    "model_etudiant_distille.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_distille.keras\")\n",
    "model_etudiant_distille.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a45af9-5d73-4cee-9966-ed3482f19da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...a100.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 108.38 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t1_a100.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_temoin.keras\n",
    "model_etudiant_temoin = new_modele_resnet()\n",
    "model_etudiant_temoin.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_temoin.keras\")\n",
    "model_etudiant_temoin.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309eb8e8-0dc7-4f69-995f-d251de46a93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def load_cifar_test():\n",
    "    _, test_dataset = cifar100.load_data()\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(test_dataset).map(preprocessing, num_parallel_calls = tf.data.AUTOTUNE).batch(batch_size).map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    return test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25123768-589d-48a8-b873-64990eb7722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def argmax_equals(x,y):\n",
    "    return tf.equal(tf.argmax(x, axis = 1), tf.argmax(y, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aceeaa7-7973-4d98-8897-28ae4876d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = load_cifar_test()\n",
    "def make_burt(images, label):\n",
    "    enseignant_pred = model_enseignant(images, training = False)\n",
    "    etudiant_distille_pred = model_etudiant_distille(images, training = False)\n",
    "    etudiant_temoin_pred = model_etudiant_temoin(images, training = False)\n",
    "    bons_enseignant = argmax_equals(enseignant_pred,label)\n",
    "    bons_etudiant_temoin = argmax_equals(etudiant_temoin_pred, label)\n",
    "    bons_etudiant_distille = argmax_equals(etudiant_distille_pred, label)\n",
    "    tdc = tf.cast(\n",
    "        tf.stack([bons_enseignant,\n",
    "                  tf.math.logical_not(bons_enseignant),\n",
    "                  bons_etudiant_temoin,\n",
    "                  tf.math.logical_not(bons_etudiant_temoin),\n",
    "                  bons_etudiant_distille,\n",
    "                  tf.math.logical_not(bons_etudiant_distille)],\n",
    "                  axis=1),\n",
    "        tf.int32)\n",
    "    burt = tf.linalg.matmul(tf.transpose(tdc),tdc)\n",
    "    return burt\n",
    "\n",
    "burt = test_dataset.map(make_burt, num_parallel_calls = tf.data.AUTOTUNE).prefetch(tf.data.AUTOTUNE).reduce(0, lambda x, y: x + y).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abca4e84-3474-46a6-9e6e-bf3221140199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7651,    0, 6525, 1126, 6447, 1204],\n",
       "       [   0, 2349,  748, 1601,  671, 1678],\n",
       "       [6525,  748, 7273,    0, 6265, 1008],\n",
       "       [1126, 1601,    0, 2727,  853, 1874],\n",
       "       [6447,  671, 6265,  853, 7118,    0],\n",
       "       [1204, 1678, 1008, 1874,    0, 2882]], dtype=int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01495841-325a-4ec2-b97b-861668fd846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100. ,   0. ,  85.3,  14.7,  84.3,  15.7],\n",
       "       [  0. , 100. ,  31.8,  68.2,  28.6,  71.4],\n",
       "       [ 89.7,  10.3, 100. ,   0. ,  86.1,  13.9],\n",
       "       [ 41.3,  58.7,   0. , 100. ,  31.3,  68.7],\n",
       "       [ 90.6,   9.4,  88. ,  12. , 100. ,   0. ],\n",
       "       [ 41.8,  58.2,  35. ,  65. ,   0. , 100. ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "burt_lignes = np.apply_along_axis(lambda x: np.round(x/x.sum()*300, 1), 1, burt)\n",
    "burt_lignes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6198bfdd-cb8f-41af-b8df-e0caae52cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...lignes.csv: 900 B / 900 B ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 7.75 KiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b]11;?\u001b\\\u001b[6n\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"sauvegardes/burt.csv\", burt, delimiter = \",\")\n",
    "np.savetxt(\"sauvegardes/burt_lignes.csv\", burt_lignes, delimiter = \",\")\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/burt.csv s3/afeldmann/projet_cnam/burt.csv\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/burt_lignes.csv s3/afeldmann/projet_cnam/burt_lignes.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f82db-3669-430c-afcd-cc1e1158bb55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
