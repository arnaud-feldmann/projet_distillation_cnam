{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kc8YkE46d5Sk",
    "outputId": "cfd3c208-2b49-47aa-a433-f2ea43363125"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/mamba/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: tensorflow_model_optimization in /opt/mamba/lib/python3.12/site-packages (0.8.0)\n",
      "Requirement already satisfied: tf_keras in /opt/mamba/lib/python3.12/site-packages (2.16.0)\n",
      "Requirement already satisfied: image_classifiers in /opt/mamba/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/mamba/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: absl-py~=1.2 in /opt/mamba/lib/python3.12/site-packages (from tensorflow_model_optimization) (1.4.0)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow_model_optimization) (0.1.8)\n",
      "Requirement already satisfied: six~=1.14 in /opt/mamba/lib/python3.12/site-packages (from tensorflow_model_optimization) (1.16.0)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /opt/mamba/lib/python3.12/site-packages (from tf_keras) (2.16.1)\n",
      "Requirement already satisfied: keras-applications<=1.0.8,>=1.0.7 in /opt/mamba/lib/python3.12/site-packages (from image_classifiers) (1.0.8)\n",
      "Requirement already satisfied: h5py in /opt/mamba/lib/python3.12/site-packages (from keras-applications<=1.0.8,>=1.0.7->image_classifiers) (3.11.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.31.0)\n",
      "Requirement already satisfied: setuptools in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (69.5.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (1.62.2)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /opt/mamba/lib/python3.12/site-packages (from tensorflow<2.17,>=2.16->tf_keras) (3.3.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/mamba/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf_keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/mamba/lib/python3.12/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/mamba/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf_keras) (2024.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/mamba/lib/python3.12/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/mamba/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf_keras) (2.1.5)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/mamba/lib/python3.12/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/mamba/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf_keras) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:55:35.302732: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-05 19:55:35.375360: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 19:55:36.500461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib tensorflow_model_optimization tf_keras image_classifiers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tf_keras as keras\n",
    "from tf_keras.applications import ResNet50V2\n",
    "from tf_keras.datasets import cifar100\n",
    "from tf_keras import Sequential, Input\n",
    "from tf_keras.layers import Dense, Dropout, RandomFlip, RandomTranslation, RandomRotation,RandomBrightness, RandomContrast, RandomZoom, GlobalAveragePooling2D\n",
    "from tf_keras.applications.resnet_v2 import preprocess_input\n",
    "from tf_keras.models import Model\n",
    "from tf_keras.activations import linear\n",
    "from classification_models.models_factory import ModelsFactory\n",
    "import tempfile\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KerasModelsFactory(ModelsFactory):\n",
    "    @staticmethod\n",
    "    def get_kwargs():\n",
    "        return {\n",
    "            'backend': keras.backend,\n",
    "            'layers': keras.layers,\n",
    "            'models': keras.models,\n",
    "            'utils': keras.utils,\n",
    "        }\n",
    "# Pour faire marcher image-classifiers avec tf_keras, la version compatibilité de tf.keras, nécéssaire pour tflite\n",
    "Classifiers = KerasModelsFactory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "batch_size = 100\n",
    "num_classes = 100\n",
    "n_images = 50000 # Pour l'entrainement, et 10000 pour le test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uPDP8KyWfCat"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...nant.keras: 135.73 MiB / 135.73 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 110.58 MiB/s 1s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:55:44.411872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13290 MB memory:  -> device: 0, name: NVIDIA A2, pci bus id: 0000:ca:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/modele_enseignant.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\n",
    "model_enseignant = Sequential([\n",
    "    Input((224,224,3)),\n",
    "    ResNet50V2(include_top=False, weights='imagenet', pooling=\"avg\"),\n",
    "    Dropout(0.25),\n",
    "    Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "])\n",
    "# Keras 3.1.1 est buggé et le chargement direct ne marche pas ici, même si les poids sont bien enregistrés\n",
    "model_enseignant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")\n",
    "\n",
    "model_enseignant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modele_logits(modele):\n",
    "    config = modele.layers[-1].get_config()\n",
    "    config['activation'] = linear\n",
    "    config['name'] = 'logits'\n",
    "    res = Model(inputs=modele.inputs, outputs=[Dense(**config)(modele.layers[-2].output)])\n",
    "    res.layers[-1].set_weights([x.numpy() for x in modele.layers[-1].weights])\n",
    "    res.compile(metrics=['accuracy'])\n",
    "    return res\n",
    "\n",
    "model_enseignant_logits = get_modele_logits(model_enseignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet18():\n",
    "    resnet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet = resnet18((224, 224, 3), weights='imagenet', include_top=False)\n",
    "    resnet_output = GlobalAveragePooling2D()(resnet.output)\n",
    "    resnet = Model(inputs=resnet.input, outputs=resnet_output)\n",
    "    return resnet\n",
    "\n",
    "def new_modele_resnet():\n",
    "    model = Sequential([\n",
    "        Input((224,224,3)),\n",
    "        ResNet18(),\n",
    "        Dropout(0.25),\n",
    "        Dense(256, activation=\"sigmoid\", kernel_regularizer = keras.regularizers.L1(0.001)),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation=\"softmax\", kernel_regularizer = keras.regularizers.L2(0.001))\n",
    "    ])\n",
    "    model.compile(metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..._a50.keras: 43.54 MiB / 43.54 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 107.32 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Skipping variable loading for optimizer 'RMSprop', because it has 1 variables whereas the saved optimizer has 2 variables. \n"
     ]
    }
   ],
   "source": [
    "!mc cp s3/afeldmann/projet_cnam/model_etudiant_t3_a50.keras /home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant.keras\n",
    "model_etudiant = new_modele_resnet()\n",
    "model_etudiant.load_weights(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant.keras\")\n",
    "model_etudiant.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "bd51EjqzvhP7"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def softmax(logits, temp):\n",
    "    expo = tf.exp(logits / temp)\n",
    "    return expo / tf.reduce_sum(expo, axis = 1, keepdims=True)\n",
    "\n",
    "def preprocessing(image, label):\n",
    "    image = tf.image.resize(image, (224, 224))\n",
    "    label = tf.squeeze(tf.one_hot(label, depth = num_classes), axis = 0)\n",
    "    return  image, label\n",
    "\n",
    "augmentation_donnees_keras = Sequential([\n",
    "    RandomFlip(\"horizontal\"),\n",
    "    RandomTranslation(0.2,0.2),\n",
    "    RandomRotation(0.2),\n",
    "    RandomZoom(0.2),\n",
    "    RandomContrast(0.2),\n",
    "    RandomBrightness(0.2,value_range=(0,1))\n",
    "])\n",
    "\n",
    "def augmentation_donnees(image, label):\n",
    "    return augmentation_donnees_keras(image/255.0, training = True)*255.0, label\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    return preprocess_input(image), label\n",
    "\n",
    "def mix_labels(image,label):\n",
    "    logits = model_enseignant_logits(image, training = False)\n",
    "    label = (softmax(logits,3) + label) / 2\n",
    "    return image, label\n",
    "\n",
    "train_dataset, test_dataset = cifar100.load_data()\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(train_dataset)\n",
    "    .map(preprocessing)\n",
    "    .cache()\n",
    "    .shuffle(n_images)\n",
    "    .batch(batch_size)\n",
    "    .map(augmentation_donnees, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .map(preprocess_resnet, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .map(mix_labels, num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(test_dataset)\n",
    "    .map(preprocessing)\n",
    "    .batch(batch_size)\n",
    "    .map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_step = np.ceil(n_images / batch_size).astype(np.int32) * n_epoch\n",
    "\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.20,\n",
    "                                                               final_sparsity=0.60,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_etudiant_pruning = tfmot.sparsity.keras.prune_low_magnitude(model_etudiant, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 19:57:26.994233: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8900\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714939077.998705   90877 service.cc:145] XLA service 0x7f4a003c2ec0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714939077.998842   90877 service.cc:153]   StreamExecutor device (0): NVIDIA A2, Compute Capability 8.6\n",
      "I0000 00:00:1714939084.482713   90877 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500/500 [==============================] - 470s 640ms/step - loss: 10.5920 - accuracy: 0.6820\n",
      "Epoch 2/10\n",
      "500/500 [==============================] - 407s 785ms/step - loss: 9.8944 - accuracy: 0.7152\n",
      "Epoch 3/10\n",
      "500/500 [==============================] - 411s 810ms/step - loss: 9.3136 - accuracy: 0.7258\n",
      "Epoch 4/10\n",
      "500/500 [==============================] - 403s 773ms/step - loss: 8.8127 - accuracy: 0.7264\n",
      "Epoch 5/10\n",
      "500/500 [==============================] - 400s 767ms/step - loss: 8.3976 - accuracy: 0.7272\n",
      "Epoch 6/10\n",
      "500/500 [==============================] - 402s 772ms/step - loss: 8.0605 - accuracy: 0.7254\n",
      "Epoch 7/10\n",
      "500/500 [==============================] - 406s 774ms/step - loss: 7.7973 - accuracy: 0.7259\n",
      "Epoch 8/10\n",
      "500/500 [==============================] - 387s 740ms/step - loss: 7.5884 - accuracy: 0.7229\n",
      "Epoch 9/10\n",
      "500/500 [==============================] - 403s 774ms/step - loss: 7.4205 - accuracy: 0.7224\n",
      "Epoch 10/10\n",
      "500/500 [==============================] - 386s 744ms/step - loss: 7.2744 - accuracy: 0.7257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.callbacks.History at 0x7f4d77f0a690>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "model_etudiant_pruning.compile(optimizer=keras.optimizers.SGD(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_etudiant_pruning.fit(train_dataset, callbacks=callbacks, epochs=n_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_pruning.keras` -> `s3/afeldmann/projet_cnam/model_etudiant_pruning.keras`\n",
      "Total: 173.50 MiB, Transferred: 173.50 MiB, Speed: 220.74 MiB/s\n",
      "`/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant_pruning_logs.csv` -> `s3/afeldmann/projet_cnam/model_etudiant_pruning_logs.csv`\n",
      "Total: 154 B, Transferred: 154 B, Speed: 1.72 KiB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom_modele =  f\"model_etudiant_pruning\"\n",
    "wd = os.getcwd()\n",
    "model_etudiant_pruning.save(f\"{wd}/sauvegardes/{nom_modele}.keras\")\n",
    "os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}.keras s3/afeldmann/projet_cnam/{nom_modele}.keras\")\n",
    "os.system(f\"mc cp {wd}/sauvegardes/{nom_modele}_logs.csv s3/afeldmann/projet_cnam/{nom_modele}_logs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 24s 119ms/step - loss: 3.9977 - accuracy: 0.7719\n",
      "100/100 [==============================] - 67s 594ms/step - loss: 3.9977 - accuracy: 0.7744\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.9977033138275146, 0.774399995803833]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_etudiant_pruning.compile(metrics=\"accuracy\")\n",
    "model_etudiant_pruning.evaluate(test_dataset)\n",
    "model_etudiant_pruning.evaluate(test_dataset.map(lambda images, labels: (images,model_enseignant(images, training = False)), num_parallel_calls = tf.data.AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7nkO80TA8Di2",
    "outputId": "30f808df-b05d-4b70-87db-66fbc0a80dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_90549/2267512799.py:3: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native TF-Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "pruned_keras_file = \"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant_pruning.h5\"\n",
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_etudiant_pruning)\n",
    "keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nS6JihkL9dcL",
    "outputId": "664d79e8-36bf-42b5-d68b-88e6c1441de6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7ds_4183/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp7ds_4183/assets\n",
      "W0000 00:00:1714944617.616395   90549 tf_tfl_flatbuffer_helpers.cc:390] Ignored output_format.\n",
      "W0000 00:00:1714944617.616442   90549 tf_tfl_flatbuffer_helpers.cc:393] Ignored drop_control_dependency.\n",
      "2024-05-05 21:30:17.616738: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /tmp/tmp7ds_4183\n",
      "2024-05-05 21:30:17.630934: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
      "2024-05-05 21:30:17.630964: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /tmp/tmp7ds_4183\n",
      "2024-05-05 21:30:17.725272: I tensorflow/cc/saved_model/loader.cc:234] Restoring SavedModel bundle.\n",
      "2024-05-05 21:30:17.986315: I tensorflow/cc/saved_model/loader.cc:218] Running initialization op on SavedModel bundle at path: /tmp/tmp7ds_4183\n",
      "2024-05-05 21:30:18.065788: I tensorflow/cc/saved_model/loader.cc:317] SavedModel load for tags { serve }; Status: success: OK. Took 449054 microseconds.\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "pruned_tflite_model = converter.convert()\n",
    "pruned_tflite_file = \"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant_pruning.tflite\"\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-lFfpMf_ncg",
    "outputId": "c8095dae-df05-4214-a4fb-b9b05bed72d1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "999it [02:26, 15.28it/s]2024-05-05 21:32:55.252805: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "1000it [02:26,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 prédictions correctes sur 1000 face aux étiquettes dures et 770 face aux étiquettes douces.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_batches = (\n",
    "    test_dataset\n",
    "    .map(lambda images, labels: (images,labels,model_enseignant(images, training = False)), num_parallel_calls = tf.data.AUTOTUNE)\n",
    "    .unbatch()\n",
    "    .batch(1)\n",
    ")\n",
    "\n",
    "interpreter = tf.lite.Interpreter(model_path=pruned_tflite_file)\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "test_etupreds, test_labels, test_enspreds = [], [], []\n",
    "for img, label, enspred in tqdm(test_batches.take(1000)):\n",
    "    interpreter.set_tensor(input_index, img)\n",
    "    interpreter.invoke()\n",
    "    test_etupreds.append(interpreter.get_tensor(output_index))\n",
    "    test_labels.append(label.numpy()[0])\n",
    "    test_enspreds.append(enspred.numpy()[0])\n",
    "\n",
    "score_dur, score_dis = 0, 0\n",
    "for item in range(0,len(test_etupreds)):\n",
    "    etupred = np.argmax(test_etupreds[item])\n",
    "    label = np.argmax(test_labels[item])\n",
    "    enspred = np.argmax(test_enspreds[item])\n",
    "    if etupred == label:\n",
    "        score_dur += 1\n",
    "    if etupred == enspred:\n",
    "        score_dis += 1\n",
    "\n",
    "print(f\"{score_dur} prédictions correctes sur 1000 face aux étiquettes dures et {score_dis} face aux étiquettes douces.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du modèle enseignant zippé : 131559019.00 bytes\n",
      "Taille du modèle étudiant zippé : 42144643.00 bytes\n",
      "Taille du modèle étudiant zippé après élagage : 21795854.00 bytes\n",
      "Taille du modèle étudiant zippé après élagage et quantification : 6221354.00 bytes\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille du modèle enseignant zippé : %.2f bytes\" % (get_gzipped_model_size(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_enseignant.keras\")))\n",
    "print(\"Taille du modèle étudiant zippé : %.2f bytes\" % (get_gzipped_model_size(\"/home/onyxia/work/projet_distillation_cnam/sauvegardes/model_etudiant.keras\")))\n",
    "print(\"Taille du modèle étudiant zippé après élagage : %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)))\n",
    "print(\"Taille du modèle étudiant zippé après élagage et quantification : %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...pruning.h5: 43.42 MiB / 43.42 MiB ┃▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓▓┃ 99.89 MiB/s 0s\u001b[0;22m\u001b[0m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b]11;?\u001b\\\u001b[6n\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m\u001b[m\u001b[32;1m"
     ]
    }
   ],
   "source": [
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant_pruning.tflite s3/afeldmann/projet_cnam/modele_etudiant_pruning.tflite\n",
    "!mc cp /home/onyxia/work/projet_distillation_cnam/sauvegardes/modele_etudiant_pruning.h5 s3/afeldmann/projet_cnam/modele_etudiant_pruning.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOKJ8xfxqA35dOVM+IFKB3Q",
   "gpuType": "A100",
   "machine_shape": "hm",
   "mount_file_id": "1zfo5zNxKu097eBmdA-BrPQHD7kJFJxRZ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
